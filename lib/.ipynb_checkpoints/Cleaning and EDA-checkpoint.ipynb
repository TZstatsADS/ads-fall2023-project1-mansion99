{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795eee2f",
   "metadata": {},
   "source": [
    "<style  type=\"text/css\"> \n",
    "cool {\n",
    "  width: 100px;\n",
    "  height: 100px;\n",
    "  background-color: red;\n",
    "  position: relative;\n",
    "  -webkit-animation-name: example; /* Safari 4.0 - 8.0 */\n",
    "  -webkit-animation-duration: 4s; /* Safari 4.0 - 8.0 */\n",
    "  -webkit-animation-iteration-count: infinite; /* Safari 4.0 - 8.0 */\n",
    "  animation-name: example;\n",
    "  animation-duration: 4s;\n",
    "  animation-iteration-count: infinite;\n",
    "}\n",
    "\n",
    "/* Safari 4.0 - 8.0 */\n",
    "@-webkit-keyframes example {\n",
    "  0%   {background-color:red; left:0px; top:0px;}\n",
    "  25%  {background-color:yellow; left:200px; top:0px;}\n",
    "  50%  {background-color:blue; left:200px; top:200px;}\n",
    "  75%  {background-color:green; left:0px; top:200px;}\n",
    "  100% {background-color:red; left:0px; top:0px;}\n",
    "}\n",
    "\n",
    "/* Standard syntax */\n",
    "@keyframes example {\n",
    "  0%   {background-color:red; left:0px; top:0px;}\n",
    "  25%  {background-color:yellow; left:200px; top:0px;}\n",
    "  50%  {background-color:blue; left:200px; top:200px;}\n",
    "  75%  {background-color:green; left:0px; top:200px;}\n",
    "  100% {background-color:red; left:0px; top:0px;}\n",
    "}\n",
    "</style>\n",
    "\n",
    "<b><center>\n",
    "<span style=\"font-size: 24pt; line-height: 1.2\">\n",
    "STAT GU4243: Applied Data Science<br>\n",
    "Fall 2023, \n",
    "</span>\n",
    "</center></b>\n",
    "<br>\n",
    "<p>\n",
    "<i><center>\n",
    "<span style=\"font-size: 20pt; line-height: 1.2\">\n",
    "Project 1: Data Story on Happy Moments<br>\n",
    "</span>\n",
    "</center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8cb960",
   "metadata": {},
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c57e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11aa9419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mansi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 0 - Load all the required libraries\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Step 1 - Load the data to be cleaned and processed\n",
    "urlfile = 'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/cleaned_hm.csv'\n",
    "hm_data = pd.read_csv(urlfile)\n",
    "\n",
    "# Step 2 - Preliminary cleaning of text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([c for c in text if c not in ('!', '.', ':', ',', '?', '(', ')', '-', '_')])\n",
    "    text = ' '.join([word for word in text.split() if word.isalpha()])\n",
    "    return text\n",
    "\n",
    "hm_data['cleaned_hm'] = hm_data['cleaned_hm'].apply(clean_text)\n",
    "\n",
    "# Step 3 - Stemming words and creating a dictionary for stem completion\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_and_create_dict(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(stems), dict(Counter(tokens))\n",
    "\n",
    "hm_data['stems'], hm_data['stem_dict'] = zip(*hm_data['cleaned_hm'].apply(stem_and_create_dict))\n",
    "\n",
    "# Step 4 - Creating a frequency dictionary to be used for stem completion\n",
    "frequency_dict = Counter()\n",
    "for stem_dict in hm_data['stem_dict']:\n",
    "    frequency_dict.update(stem_dict)\n",
    "\n",
    "# Step 5 - Removing stopwords that don't hold any significant information for our data set\n",
    "custom_stop_words = [\"happy\", \"ago\", \"yesterday\", \"lot\", \"today\", \"months\", \"month\", \"happier\", \"happiest\", \"last\", \"week\", \"past\"]\n",
    "all_stop_words = ENGLISH_STOP_WORDS.union(custom_stop_words)\n",
    "\n",
    "# Step 6 - Combining stems and dictionary into a dataframe\n",
    "def stem_completion(stem_text, stem_dict):\n",
    "    completed_text = []\n",
    "    for stem in stem_text.split():\n",
    "        if stem not in all_stop_words:\n",
    "            completed_text.append(str(stem_dict.get(stem, stem)))\n",
    "        else:\n",
    "            completed_text.append(stem)\n",
    "    return ' '.join(completed_text)\n",
    "\n",
    "hm_data['completed_text'] = hm_data.apply(lambda row: stem_completion(row['stems'], row['stem_dict']), axis=1)\n",
    "\n",
    "\n",
    "# Exporting the processed text data into a CSV file\n",
    "hm_data.to_csv(\"../output/processed_moments.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05bb5f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>ground_truth_category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>stems</th>\n",
       "      <th>stem_dict</th>\n",
       "      <th>completed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>i went on a successful date with someone i fel...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "      <td>i went on a success date with someon i felt sy...</td>\n",
       "      <td>{'i': 2, 'went': 1, 'on': 1, 'a': 1, 'successf...</td>\n",
       "      <td>i 1 on a success 1 with someon i 1 sympathi an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>2</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>i was happy when my son got marks in his exami...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "      <td>i wa happi when my son got mark in hi examin</td>\n",
       "      <td>{'i': 1, 'was': 1, 'happy': 1, 'when': 1, 'my'...</td>\n",
       "      <td>i wa happi when my 1 1 mark in hi examin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>1936</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>i went to the gym this morning and did yoga</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exercise</td>\n",
       "      <td>i went to the gym thi morn and did yoga</td>\n",
       "      <td>{'i': 1, 'went': 1, 'to': 1, 'the': 1, 'gym': ...</td>\n",
       "      <td>i 1 to the 1 thi morn and 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>206</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>we had a serious talk with some friends of our...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "      <td>we had a seriou talk with some friend of our w...</td>\n",
       "      <td>{'we': 2, 'had': 2, 'a': 2, 'serious': 1, 'tal...</td>\n",
       "      <td>we had a seriou 1 with some friend of our who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>6227</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>i went with grandchildren to butterfly display...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "      <td>i went with grandchildren to butterfli display...</td>\n",
       "      <td>{'i': 1, 'went': 1, 'with': 1, 'grandchildren'...</td>\n",
       "      <td>i 1 with 1 to butterfli 1 at 1 conservatori</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid   wid reflection_period  \\\n",
       "0  27673  2053               24h   \n",
       "1  27674     2               24h   \n",
       "2  27675  1936               24h   \n",
       "3  27676   206               24h   \n",
       "4  27677  6227               24h   \n",
       "\n",
       "                                         original_hm  \\\n",
       "0  I went on a successful date with someone I fel...   \n",
       "1  I was happy when my son got 90% marks in his e...   \n",
       "2       I went to the gym this morning and did yoga.   \n",
       "3  We had a serious talk with some friends of our...   \n",
       "4  I went with grandchildren to butterfly display...   \n",
       "\n",
       "                                          cleaned_hm  modified  num_sentence  \\\n",
       "0  i went on a successful date with someone i fel...      True             1   \n",
       "1  i was happy when my son got marks in his exami...      True             1   \n",
       "2        i went to the gym this morning and did yoga      True             1   \n",
       "3  we had a serious talk with some friends of our...      True             2   \n",
       "4  i went with grandchildren to butterfly display...      True             1   \n",
       "\n",
       "  ground_truth_category predicted_category  \\\n",
       "0                   NaN          affection   \n",
       "1                   NaN          affection   \n",
       "2                   NaN           exercise   \n",
       "3               bonding            bonding   \n",
       "4                   NaN          affection   \n",
       "\n",
       "                                               stems  \\\n",
       "0  i went on a success date with someon i felt sy...   \n",
       "1       i wa happi when my son got mark in hi examin   \n",
       "2            i went to the gym thi morn and did yoga   \n",
       "3  we had a seriou talk with some friend of our w...   \n",
       "4  i went with grandchildren to butterfli display...   \n",
       "\n",
       "                                           stem_dict  \\\n",
       "0  {'i': 2, 'went': 1, 'on': 1, 'a': 1, 'successf...   \n",
       "1  {'i': 1, 'was': 1, 'happy': 1, 'when': 1, 'my'...   \n",
       "2  {'i': 1, 'went': 1, 'to': 1, 'the': 1, 'gym': ...   \n",
       "3  {'we': 2, 'had': 2, 'a': 2, 'serious': 1, 'tal...   \n",
       "4  {'i': 1, 'went': 1, 'with': 1, 'grandchildren'...   \n",
       "\n",
       "                                      completed_text  \n",
       "0  i 1 on a success 1 with someon i 1 sympathi an...  \n",
       "1           i wa happi when my 1 1 mark in hi examin  \n",
       "2                      i 1 to the 1 thi morn and 1 1  \n",
       "3  we had a seriou 1 with some friend of our who ...  \n",
       "4        i 1 with 1 to butterfli 1 at 1 conservatori  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = pd.read_csv(\"../output/processed_moments.csv\")\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "298d0f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100535 entries, 0 to 100534\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count   Dtype \n",
      "---  ------                 --------------   ----- \n",
      " 0   hmid                   100535 non-null  int64 \n",
      " 1   wid                    100535 non-null  int64 \n",
      " 2   reflection_period      100535 non-null  object\n",
      " 3   original_hm            100535 non-null  object\n",
      " 4   cleaned_hm             100535 non-null  object\n",
      " 5   modified               100535 non-null  bool  \n",
      " 6   num_sentence           100535 non-null  int64 \n",
      " 7   ground_truth_category  14125 non-null   object\n",
      " 8   predicted_category     100535 non-null  object\n",
      " 9   stems                  100535 non-null  object\n",
      " 10  stem_dict              100535 non-null  object\n",
      " 11  completed_text         100535 non-null  object\n",
      "dtypes: bool(1), int64(3), object(8)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d068fe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wid</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital</th>\n",
       "      <th>parenthood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>married</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>IND</td>\n",
       "      <td>m</td>\n",
       "      <td>married</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>IND</td>\n",
       "      <td>m</td>\n",
       "      <td>single</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>married</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>married</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wid   age country gender  marital parenthood\n",
       "0    1  37.0     USA      m  married          y\n",
       "1    2  29.0     IND      m  married          y\n",
       "2    3    25     IND      m   single          n\n",
       "3    4    32     USA      m  married          y\n",
       "4    5    29     USA      m  married          y"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the Demographics Data \n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv\"\n",
    "demographic_df = pd.read_csv(url)\n",
    "demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b10ba9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10844 entries, 0 to 10843\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   wid         10844 non-null  int64 \n",
      " 1   age         10809 non-null  object\n",
      " 2   country     10771 non-null  object\n",
      " 3   gender      10812 non-null  object\n",
      " 4   marital     10787 non-null  object\n",
      " 5   parenthood  10813 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 508.4+ KB\n"
     ]
    }
   ],
   "source": [
    "demographic_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345309fa",
   "metadata": {},
   "source": [
    "**Merging the two datasets to perform exploratory data analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61609f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>ground_truth_category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>stems</th>\n",
       "      <th>stem_dict</th>\n",
       "      <th>completed_text</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital</th>\n",
       "      <th>parenthood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>i went on a successful date with someone i fel...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "      <td>i went on a success date with someon i felt sy...</td>\n",
       "      <td>{'i': 2, 'went': 1, 'on': 1, 'a': 1, 'successf...</td>\n",
       "      <td>i 1 on a success 1 with someon i 1 sympathi an...</td>\n",
       "      <td>35</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>single</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27873</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>I played a new game that was fun and got to en...</td>\n",
       "      <td>i played a new game that was fun and got to en...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leisure</td>\n",
       "      <td>i play a new game that wa fun and got to enjoy...</td>\n",
       "      <td>{'i': 1, 'played': 1, 'a': 1, 'new': 1, 'game'...</td>\n",
       "      <td>i play a 1 1 that wa 1 and 1 to 1 the mechan o...</td>\n",
       "      <td>35</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>single</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28073</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>I listened to some music and heard an entire a...</td>\n",
       "      <td>i listened to some music and heard an entire a...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leisure</td>\n",
       "      <td>i listen to some music and heard an entir albu...</td>\n",
       "      <td>{'i': 2, 'listened': 1, 'to': 1, 'some': 1, 'm...</td>\n",
       "      <td>i listen to some 1 and 2 an entir 1 i 2 more t...</td>\n",
       "      <td>35</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>single</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33522</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>Went to see a movie with my friend</td>\n",
       "      <td>went to see a movie with my friend</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bonding</td>\n",
       "      <td>went to see a movi with my friend</td>\n",
       "      <td>{'went': 1, 'to': 1, 'see': 1, 'a': 1, 'movie'...</td>\n",
       "      <td>1 to see a movi with my 1</td>\n",
       "      <td>35</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>single</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34522</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>Played guitar, learning a song on it</td>\n",
       "      <td>played guitar learning a song on it</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leisure</td>\n",
       "      <td>play guitar learn a song on it</td>\n",
       "      <td>{'played': 1, 'guitar': 1, 'learning': 1, 'a':...</td>\n",
       "      <td>play 1 learn a 1 on it</td>\n",
       "      <td>35</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>single</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid   wid reflection_period  \\\n",
       "0  27673  2053               24h   \n",
       "1  27873  2053               24h   \n",
       "2  28073  2053               24h   \n",
       "3  33522  2053               24h   \n",
       "4  34522  2053               24h   \n",
       "\n",
       "                                         original_hm  \\\n",
       "0  I went on a successful date with someone I fel...   \n",
       "1  I played a new game that was fun and got to en...   \n",
       "2  I listened to some music and heard an entire a...   \n",
       "3                 Went to see a movie with my friend   \n",
       "4               Played guitar, learning a song on it   \n",
       "\n",
       "                                          cleaned_hm  modified  num_sentence  \\\n",
       "0  i went on a successful date with someone i fel...      True             1   \n",
       "1  i played a new game that was fun and got to en...      True             1   \n",
       "2  i listened to some music and heard an entire a...      True             1   \n",
       "3                 went to see a movie with my friend      True             1   \n",
       "4                played guitar learning a song on it      True             1   \n",
       "\n",
       "  ground_truth_category predicted_category  \\\n",
       "0                   NaN          affection   \n",
       "1                   NaN            leisure   \n",
       "2                   NaN            leisure   \n",
       "3                   NaN            bonding   \n",
       "4                   NaN            leisure   \n",
       "\n",
       "                                               stems  \\\n",
       "0  i went on a success date with someon i felt sy...   \n",
       "1  i play a new game that wa fun and got to enjoy...   \n",
       "2  i listen to some music and heard an entir albu...   \n",
       "3                  went to see a movi with my friend   \n",
       "4                     play guitar learn a song on it   \n",
       "\n",
       "                                           stem_dict  \\\n",
       "0  {'i': 2, 'went': 1, 'on': 1, 'a': 1, 'successf...   \n",
       "1  {'i': 1, 'played': 1, 'a': 1, 'new': 1, 'game'...   \n",
       "2  {'i': 2, 'listened': 1, 'to': 1, 'some': 1, 'm...   \n",
       "3  {'went': 1, 'to': 1, 'see': 1, 'a': 1, 'movie'...   \n",
       "4  {'played': 1, 'guitar': 1, 'learning': 1, 'a':...   \n",
       "\n",
       "                                      completed_text age country gender  \\\n",
       "0  i 1 on a success 1 with someon i 1 sympathi an...  35     USA      m   \n",
       "1  i play a 1 1 that wa 1 and 1 to 1 the mechan o...  35     USA      m   \n",
       "2  i listen to some 1 and 2 an entir 1 i 2 more t...  35     USA      m   \n",
       "3                          1 to see a movi with my 1  35     USA      m   \n",
       "4                             play 1 learn a 1 on it  35     USA      m   \n",
       "\n",
       "  marital parenthood  \n",
       "0  single          n  \n",
       "1  single          n  \n",
       "2  single          n  \n",
       "3  single          n  \n",
       "4  single          n  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df = pd.merge(cleaned_df, demographic_df, on='wid', validate = 'm:1')\n",
    "happy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec97cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100535 entries, 0 to 100534\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype \n",
      "---  ------                 --------------   ----- \n",
      " 0   hmid                   100535 non-null  int64 \n",
      " 1   wid                    100535 non-null  int64 \n",
      " 2   reflection_period      100535 non-null  object\n",
      " 3   original_hm            100535 non-null  object\n",
      " 4   cleaned_hm             100535 non-null  object\n",
      " 5   modified               100535 non-null  bool  \n",
      " 6   num_sentence           100535 non-null  int64 \n",
      " 7   ground_truth_category  14125 non-null   object\n",
      " 8   predicted_category     100535 non-null  object\n",
      " 9   stems                  100535 non-null  object\n",
      " 10  stem_dict              100535 non-null  object\n",
      " 11  completed_text         100535 non-null  object\n",
      " 12  age                    100442 non-null  object\n",
      " 13  country                100332 non-null  object\n",
      " 14  gender                 100456 non-null  object\n",
      " 15  marital                100378 non-null  object\n",
      " 16  parenthood             100457 non-null  object\n",
      "dtypes: bool(1), int64(3), object(13)\n",
      "memory usage: 13.1+ MB\n"
     ]
    }
   ],
   "source": [
    "happy_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62deec66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100535, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8bb56ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmid                         0\n",
      "wid                          0\n",
      "reflection_period            0\n",
      "original_hm                  0\n",
      "cleaned_hm                   0\n",
      "modified                     0\n",
      "num_sentence                 0\n",
      "ground_truth_category    86410\n",
      "predicted_category           0\n",
      "stems                        0\n",
      "stem_dict                    0\n",
      "completed_text               0\n",
      "age                         93\n",
      "country                    203\n",
      "gender                      79\n",
      "marital                    157\n",
      "parenthood                  78\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = happy_df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07855955",
   "metadata": {},
   "source": [
    "#  Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4931d9ed",
   "metadata": {},
   "source": [
    "Perform exploratory data analysis to find trends, patterns, insights and understand the relationships between each of the attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108145e3",
   "metadata": {},
   "source": [
    "__1) Anaylysis of sentences submitted by users__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b622e5",
   "metadata": {},
   "source": [
    "Calculation of the number of words used in the sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6267abbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100535.000000\n",
       "mean         17.947929\n",
       "std          20.997203\n",
       "min           1.000000\n",
       "25%           9.000000\n",
       "50%          13.000000\n",
       "75%          20.000000\n",
       "max        1164.000000\n",
       "Name: cleaned_hm, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = happy_df[happy_df['cleaned_hm'].notnull()]\n",
    "len_count = cleaned_df['cleaned_hm'].apply(lambda x: len(x.split()))\n",
    "len_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c0c2534",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m length_counts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(length_category\u001b[38;5;241m.\u001b[39mvalue_counts())\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      5\u001b[0m length_counts\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Words\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m sns\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Words\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mlength_counts, order\u001b[38;5;241m=\u001b[39mlength_order)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "length_order = [\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\", \"25-29\", \"30-34\", \"35-39\", \\\n",
    "                \"40-44\", \"45-49\", \">=50\"]\n",
    "length_category = len_count.apply(lambda x: length_order[min(10, int(x/5))])\n",
    "length_counts = pd.DataFrame(length_category.value_counts()).reset_index()\n",
    "length_counts.columns = ['Number of Words', 'Count']\n",
    "\n",
    "sns.barplot(x='Number of Words', y='Count', data=length_counts, order=length_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd19ade",
   "metadata": {},
   "source": [
    "Majority of the responses have 5 - 24 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da085ca",
   "metadata": {},
   "source": [
    "Calculation of frequency of words used  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da910b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['token_count'] = cleaned_df['cleaned_hm'].apply(lambda x: len(str(x).split()))\n",
    "average_token_count = cleaned_df['token_count'].mean()\n",
    "print(f\"The average token count is: {average_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c92303",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(cleaned_df['cleaned_hm'].tolist())\n",
    "text = text.lower()\n",
    "wordcloud = WordCloud(background_color=\"white\", height=2700, width=3600).generate(text)\n",
    "plt.figure( figsize=(15,8) )\n",
    "plt.imshow(wordcloud.recolor(colormap=plt.get_cmap('Set2')), interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eed1f9c",
   "metadata": {},
   "source": [
    "In this WordCloud, there are many noisy words such as \"got\", \"went\", \"made\" etc which need to be removed to get a more clear idea of what made people the most happy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eefd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT_WORDS = ['happy', 'day', 'got', 'went', 'today','make', 'came','go','made', 'one', 'two', 'time', 'last', 'first', 'going', 'getting', 'took', 'found', 'lot', 'really', 'saw', 'see', 'month', 'week', 'day', 'yesterday', 'year', 'ago', 'now', 'still', 'since', 'something', 'great', 'good', 'long', 'thing', 'toi', 'without', 'yesteri', '2s', 'toand', 'ing']\n",
    "\n",
    "text = ' '.join(cleaned_df['cleaned_hm'].tolist())\n",
    "text = text.lower()\n",
    "for w in LIMIT_WORDS:\n",
    "    text = text.replace(' ' + w, '')\n",
    "    text = text.replace(w + ' ', '')\n",
    "wordcloud = WordCloud(background_color=\"white\", height=2700, width=3600).generate(text)\n",
    "plt.figure( figsize=(15,8) )\n",
    "plt.imshow(wordcloud.recolor(colormap=plt.get_cmap('Set2')), interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ffe72",
   "metadata": {},
   "source": [
    "From this Wordcloud, we can understand that the most commonly used words in the responses were friend, work, getting something new, ability to do something. This information can be used in further anaylysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c957583",
   "metadata": {},
   "source": [
    "__2) Calculation of Happiness Score__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d47f14",
   "metadata": {},
   "source": [
    "Different scoring procedures have been added into the analytical framework in the effort to create a nuanced measure for estimating happiness scores from textual snippets.\n",
    "\n",
    "The polarity score adds a basic element to the happiness metric by measuring the intrinsic positive or negative that is ingrained within the sentence form.\n",
    "\n",
    "Sentiment Transition Score: This factor examines the change in sentiment between words in greater detail. This aspect is crucial for comprehending the emotional fluidity of the story and enables the model to pick up on minor changes in the changing moods, which helps to produce a more precise happiness score.\n",
    "\n",
    "\n",
    "Lexical Score: This score focuses on how frequently a sentence contains specific uplifting words. It gives the model the ability to recognize the lexical richness and positive emphasis in the text, giving the happiness metric a qualitative element.\n",
    "\n",
    "Context Score: The context score goes beyond the lexical and syntactic levels to examine the underlying sentiment in the textual context. It does this by using a deep learning model to comprehend the subtleties and complexities of human language, which makes the happiness score more in line with human interpretation.\n",
    "\n",
    "The model attempts to compute a happiness score that is not only quantitative but also richly layered with qualitative insights, offering a comprehensive view of the perceived happiness in textual narratives, by combining these diverse scores, each with its own unique perspective and analytical depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet as wn\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sentiment transition\n",
    "def sentiment_transition(sentence):\n",
    "    words = sentence.split()\n",
    "    transitions = []\n",
    "    for i in range(len(words)-1):\n",
    "        word1_polarity = TextBlob(words[i]).sentiment.polarity\n",
    "        word2_polarity = TextBlob(words[i+1]).sentiment.polarity\n",
    "        transitions.append(abs(word1_polarity - word2_polarity))\n",
    "    if transitions:\n",
    "        return sum(transitions)/len(transitions)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Function to calculate lexical score\n",
    "def lexical_score(sentence):\n",
    "    positive_lemmas = ['good', 'happy', 'positive', 'joyful', 'pleased', 'content', 'delighted', 'ecstatic', 'satisfied']\n",
    "    return sum(1 for word in sentence.split() if wn.synsets(word, pos=wn.ADJ) and wn.synsets(word, pos=wn.ADJ)[0].lemmas()[0].name() in positive_lemmas)\n",
    "\n",
    "# Function to calculate Context Score\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def context_score(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    if len(tokens) > 510:\n",
    "        tokens = tokens[:510]\n",
    "    sentence = tokenizer.convert_tokens_to_string(tokens)\n",
    "    \n",
    "    result = classifier(sentence)\n",
    "    score = result[0]['score'] if result[0]['label'] == 'POSITIVE' else -result[0]['score']\n",
    "    return score\n",
    "\n",
    "\n",
    "# Main function to calculate happiness score\n",
    "def calculate_happiness_score(sentence):\n",
    "    analysis = TextBlob(sentence)\n",
    "    polarity = analysis.sentiment.polarity\n",
    "    transition_score = sentiment_transition(sentence)\n",
    "    lexical = lexical_score(sentence)\n",
    "    context = context_score(sentence)\n",
    "\n",
    "    # Adjusting the weights for each score\n",
    "    weight_polarity = 0.4\n",
    "    weight_transition = 0.2\n",
    "    weight_lexical = 0.2\n",
    "    weight_context = 0.2\n",
    "    \n",
    "    happiness_score = (weight_polarity * polarity + weight_transition * transition_score + weight_lexical * lexical + weight_context * context)\n",
    "    return happiness_score\n",
    "\n",
    "# Assuming cleaned_df is already defined and loaded\n",
    "cleaned_df['happiness_score'] = cleaned_df['cleaned_hm'].apply(calculate_happiness_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_scores = cleaned_df['happiness_score']\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(happiness_scores, bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Happiness Scores')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc17da44",
   "metadata": {},
   "source": [
    "The range of the overall happiness score remains between -1 and 1. This range is maintained via the aggregation scheme and weights in the calculate_happiness_score function. The meaning of each score is as follows:\n",
    "\n",
    "A statement receives a favorable score (between 0 and 1) if it typically expresses happiness or happy feelings. A score that is more closely related to one indicates that the statement has more positivity or happiness.\n",
    "\n",
    "Zero Score (0): A zero score denotes neutrality, which means that neither a positive nor a negative attitude is clearly conveyed by the text. Either the sentence is completely neutral or the positive and negative aspects balance one another out.\n",
    "\n",
    "A statement that receives a negative score (between -1 and 0) is one that primarily conveys dissatisfaction or bad feelings. A result that is closer to -1 suggests that the statement contains a stronger negative emotion or unhappiness.\n",
    "\n",
    "This total happiness score is a composite metric that incorporates the subtle impressions of lexical positivity, sentiment transition, polarity, and context to provide a thorough evaluation of the sentence's happiness quotient. It is designed to mimic how a human might understand a piece of text, collecting both overt and subtle linguistic cues.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668601be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the insightful dataframe into a CSV file\n",
    "cleaned_df.to_csv(\"../output/final_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84def9fb",
   "metadata": {},
   "source": [
    "__3) Analyse the different data distributions and values of select columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed542df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687432a8",
   "metadata": {},
   "source": [
    "**Column - predicted_category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50046969",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_category_counts = happy_df['predicted_category'].value_counts()\n",
    "\n",
    "# Convert the value counts to a dataframe\n",
    "predicted_category_counts_df = predicted_category_counts.reset_index()\n",
    "predicted_category_counts_df.columns = ['predicted_category', 'count']\n",
    "print(predicted_category_counts_df)\n",
    "\n",
    "# Visualize the counts\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.pie(predicted_category_counts_df['count'], labels=predicted_category_counts_df['predicted_category'], autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal') \n",
    "plt.title('Distribution of Prediction Categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4a2cc",
   "metadata": {},
   "source": [
    "Most responses are in two categories namely Achievement and Affection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c247931",
   "metadata": {},
   "source": [
    "**Column - reflection_period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652765c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_period_counts = happy_df['reflection_period'].value_counts()\n",
    "\n",
    "# Convert the value counts to a dataframe\n",
    "reflection_period_counts_df = reflection_period_counts.reset_index()\n",
    "reflection_period_counts_df.columns = ['reflection_period', 'count']\n",
    "print(reflection_period_counts_df)\n",
    "\n",
    "# Visualize the counts\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.pie(reflection_period_counts_df['count'], labels=reflection_period_counts_df['reflection_period'], autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal') \n",
    "plt.title('Distribution of Reflection Periods')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271bca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sentiment polarity\n",
    "def calculate_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Apply the function to calculate sentiment polarity for each happy moment\n",
    "happy_df['sentiment_polarity'] = happy_df['cleaned_hm'].apply(calculate_sentiment)\n",
    "\n",
    "# Separate data into two groups: 24-hour and 3-month reflection periods\n",
    "group_24h = happy_df[happy_df['reflection_period'] == '24h']\n",
    "group_3m = happy_df[happy_df['reflection_period'] == '3m']\n",
    "\n",
    "# Calculate average sentiment polarity for each group\n",
    "avg_sentiment_24h = group_24h['sentiment_polarity'].mean()\n",
    "avg_sentiment_3m = group_3m['sentiment_polarity'].mean()\n",
    "\n",
    "print(f\"The average sentiment polarity for the 24-hour group is: {avg_sentiment_24h}\")\n",
    "print(f\"The average sentiment polarity for the 3-month group is: {avg_sentiment_3m}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba8b87b",
   "metadata": {},
   "source": [
    "According to the data, there is an equal distribution of reflections across a 3-month and a 24-hour period. The variation in sentiment polarity between the two groups is quite small which suggests that the general level of happiness expressed throughout both reflection times is fairly comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f380ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_categories_24h = group_24h['predicted_category'].value_counts()\n",
    "top_categories_3m = group_3m['predicted_category'].value_counts()\n",
    "\n",
    "print(top_categories_24h)\n",
    "print(top_categories_3m)\n",
    "\n",
    "# For 24h data\n",
    "wordcloud_24h = WordCloud(width = 1000, height = 500).generate_from_frequencies(top_categories_24h)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud_24h, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Top Predicted Categories for 24h')\n",
    "plt.show()\n",
    "\n",
    "# For 3m data\n",
    "wordcloud_3m = WordCloud(width = 1000, height = 500).generate_from_frequencies(top_categories_3m)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud_3m, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Top Predicted Categories for 3m')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f51812b",
   "metadata": {},
   "source": [
    "**Column - marital** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703df15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_counts = happy_df['marital'].value_counts()\n",
    "\n",
    "# Convert the value counts to a dataframe\n",
    "marital_counts_df = marital_counts.reset_index()\n",
    "marital_counts_df.columns = ['marital', 'count']\n",
    "print(marital_counts_df)\n",
    "\n",
    "# Visualize the counts\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(marital_counts_df['marital'], marital_counts_df['count'], color='teal')\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of each Marital Status')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_happiness = cleaned_df.groupby('marital')['happiness_score'].mean()\n",
    "print(marital_happiness)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='marital', y='happiness_score', data=cleaned_df)\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Happiness Score')\n",
    "plt.title('Distribution of Happiness Scores by Marital Status')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24eead0",
   "metadata": {},
   "source": [
    "The happiness scores do not significantly differ despite the various life conditions reflected in the marital statuses, suggesting a nuanced relationship between marital status and happiness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c3994",
   "metadata": {},
   "source": [
    "**Column - Country**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_counts = happy_df['country'].value_counts()\n",
    "\n",
    "# Convert the value counts to a dataframe\n",
    "country_counts_df = country_counts.reset_index()\n",
    "country_counts_df.columns = ['country', 'count']\n",
    "\n",
    "country_counts_df = country_counts_df.sort_values('count', ascending=False)\n",
    "\n",
    "non_zero_country_counts_df = country_counts_df[country_counts_df['count'] > 35]\n",
    "\n",
    "fig = px.scatter(non_zero_country_counts_df, x='country', y='count', \n",
    "                   title='Distribution of Counts per Country', \n",
    "                   labels={'country': 'Countries', 'count': 'Count'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524f948",
   "metadata": {},
   "source": [
    "**Column - parenthood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5fed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "parenthood_counts = happy_df['parenthood'].value_counts()\n",
    "\n",
    "# Convert the value counts to a dataframe\n",
    "parenthood_counts_df = parenthood_counts.reset_index()\n",
    "parenthood_counts_df.columns = ['parenthood', 'count']\n",
    "print(parenthood_counts_df)\n",
    "\n",
    "parenthood_happiness = cleaned_df.groupby('parenthood')['happiness_score'].mean()\n",
    "print(parenthood_happiness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93420b6a",
   "metadata": {},
   "source": [
    "**Column - age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_happiness = cleaned_df.groupby('age')['happiness_score'].mean()\n",
    "\n",
    "age_happiness_df = age_happiness.reset_index()\n",
    "age_happiness_df.columns = ['age', 'happiness_score']\n",
    "print(age_happiness_df)\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_age(age_str):\n",
    "    cleaned_str = re.sub(r'\\D', '', age_str)\n",
    "    return int(cleaned_str) if cleaned_str else 0\n",
    "\n",
    "age_happiness_df['age'] = age_happiness_df['age'].apply(clean_age)\n",
    "\n",
    "age_happiness_df['age'] = age_happiness_df['age'].astype(float)\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H4('Happiness Score by Age Group'),\n",
    "    dcc.RangeSlider(\n",
    "        id='range-slider',\n",
    "        min=0, max=100, step=1,\n",
    "        marks={i: str(i) for i in range(0, 101, 10)},\n",
    "        value=[17, 25]\n",
    "    ),\n",
    "    dcc.Graph(\n",
    "        id=\"histogram-plot\",\n",
    "    )\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('histogram-plot', 'figure'),\n",
    "    [Input('range-slider', 'value')]\n",
    ")\n",
    "def update_histogram(selected_range):\n",
    "    age_groups = age_happiness_df[(age_happiness_df['age'] >= selected_range[0]) & (age_happiness_df['age'] <= selected_range[1])].groupby('age')['happiness_score'].mean().reset_index()\n",
    "    fig = px.histogram(age_groups, x='age', y='happiness_score', \n",
    "                       title='Happiness Score by Age Group', \n",
    "                       labels={'age': 'Age Group', 'happiness_score': 'Average Happiness Score'})\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d42ab",
   "metadata": {},
   "source": [
    "**Column - Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b904ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_happiness = cleaned_df.groupby('gender')['happiness_score'].mean()\n",
    "print(gender_happiness)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='gender', y='happiness_score', data=cleaned_df)\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Happiness Score')\n",
    "plt.title('Distribution of Happiness Scores based on Gender')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3fa3a",
   "metadata": {},
   "source": [
    "Correlation Between various features and Happiness score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772dbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encoding categorical variables\n",
    "cleaned_df['gender_encoded'] = label_encoder.fit_transform(cleaned_df['gender'])\n",
    "cleaned_df['age_encoded'] = label_encoder.fit_transform(cleaned_df['age'])\n",
    "cleaned_df['parenthood_encoded'] = label_encoder.fit_transform(cleaned_df['parenthood'])\n",
    "cleaned_df['marital_status_encoded'] = label_encoder.fit_transform(cleaned_df['marital'])\n",
    "cleaned_df['reflection_period_encoded'] = label_encoder.fit_transform(cleaned_df['reflection_period'])\n",
    "cleaned_df['country_encoded'] = label_encoder.fit_transform(cleaned_df['country'])\n",
    "cleaned_df['predicted_category_encoded'] = label_encoder.fit_transform(cleaned_df['predicted_category'])\n",
    "\n",
    "# Selecting columns to find correlation\n",
    "columns_to_correlate = [\n",
    "    'happiness_score', \n",
    "    'gender_encoded', \n",
    "    'age_encoded',\n",
    "    'marital_status_encoded',\n",
    "    'parenthood_encoded',\n",
    "    'reflection_period_encoded', \n",
    "    'country_encoded',\n",
    "    'predicted_category_encoded'\n",
    "]\n",
    "\n",
    "# Finding correlation\n",
    "correlation_matrix = cleaned_df[columns_to_correlate].corr()\n",
    "\n",
    "\n",
    "#Visualizing the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='Blues')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703780f",
   "metadata": {},
   "source": [
    "Age has a negative correlation with the happiness_score meaning that the happiness score tends to drop when these factors rise or change.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
